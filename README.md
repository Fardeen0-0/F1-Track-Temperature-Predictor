# F1-Track-Temperature-Predictor
## üèéÔ∏èWhat is this?!
Formula 1 is an extremely technical sport and often a variety of variables influence how the team prepares their car for each race. One part of it is tyre management and that heavily depends on the track's surface and temperature. That's where this predictor comes in. As the name suggests, this software, using machine learning, helps predict track temperatures of a race track based on various weather parameters including air temperature, humidity, pressure, wind speed and direction, and rainfall.

## ‚öôÔ∏èHow does it work?
I built a regression model that is able to predict track temperatures based on the other weather parameters that it is provided with. I built the model completely from scratch (yep, no scikit!) by implementing cost computation, gradient descent, feature engineering, as well as regularization. The model was trained on track temperature data (obtained from [Kaggle](https://www.kaggle.com/datasets/quantumkaze/f1-weather-dataset-2018-2023)) that was recorded at multiple intervals throughout a race for the entire season from the years 2018 -2023. I used quadratic regression to train the model, since linear regression alone could not capture the complex trends and patterns of the data. After being trained on this humongous dataset, it was then tested on race data obtained from 2024 (source: [Huggingface](https://huggingface.co/spaces/tracinginsights/F1-analysis)) to check for accuracy.

## ü§®So.. does it really work?
To add to what I was mentioning before, I initially started off with this project to get some experience with linear regression, naively thinking that I would be able to wrap it up quickly based off of the linear regression concepts that I learnt. Little did I know that this project would make me venture outside of my comfort zone into the region of quadratic and even cubic regression. After discovering that linear regression wasn't enough to make the predictor work, I quickly tried implementing quadratic regression. On the plus side, the results improved greatly, however, it still is not pinpoint accurate and has some considerable room for improvement. 

**<ins>Further work:</ins>** \
I have currently been trying to implement cubic regression (by also regularizing it to avoid overfitting) with some success. And by some, I mean quite a tiny amount since the cost has reduced by the tenths and nothing more. Also it takes hours to train it too. Currently, I'm in a bit of a standstill since 1) I am still in the process of figuring out what else I can do, or if this is the maximum I can do and leave it at that and 2) College has started and sophomore year is being quite demanding, so I'm forced to divert attention to college work. However, I plan to complete this once I am free by trying out a few more techniques that might work out. One thing that I'm thinking as of now is to try to optimize the code further by vectorizing certain areas of it to see if that does any good.

## Final thoughts and closing
Hopefully, I can increase its accuracy further by the end. But even if I am not able to, this project was all about the journey rather than the end result. Learning all about regression and actually being able to build a model from scratch by understanding how it all functions on the inside was precious to me and was some good time spent during my summer break. Firstly would like to thank God for giving me the resilience throughout and the ability to be able to do it. Also big thanks to Andrew Ng for breaking down this rather complex concept into very simple language that I was able to understand. And finally thanks to my parents and lil bro for sticking by me.\
Until later... 
